{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8352f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import kaggle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dab1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './human-face-emotions/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abed00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57756 files belonging to 5 classes.\n",
      "Classes: ['Angry', 'Fear', 'Happy', 'Sad', 'Suprise']\n"
     ]
    }
   ],
   "source": [
    "full_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    label_mode=\"int\",\n",
    "    image_size=(48, 48),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,      # return one (img, label) at a time\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "class_names = full_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377c725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = list(full_ds.as_numpy_iterator())\n",
    "\n",
    "images = [x[0] for x in full_data]  # list of arrays\n",
    "labels = [x[1] for x in full_data]  # list of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5493558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: train vs temp (val+test)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels,\n",
    "    test_size=0.30,         # 30% → val+test\n",
    "    random_state=42,\n",
    "    stratify=labels         # keeps class proportions\n",
    ")\n",
    "\n",
    "# Second split: val vs test (each = 15%)\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_temp, y_temp,\n",
    "    test_size=0.50,         # half of 30% = 15%\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e846bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a85d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_ds = train_ds.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45ff0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a368c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(96, 96, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "#base.trainable = False  # keep pretrained weights fixed\n",
    "base.trainable = True\n",
    "for layer in base.layers[:100]: # pretrained layers for low level patterns\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(48,48,1)),\n",
    "    tf.keras.layers.Resizing(96, 96),\n",
    "    tf.keras.layers.Conv2D(3, (1,1)),  # convert grayscale -> 3 channels\n",
    "\n",
    "    base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae74371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 355ms/step - accuracy: 0.4350 - loss: 1.4128 - val_accuracy: 0.1385 - val_loss: 4.1534\n",
      "Epoch 2/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 337ms/step - accuracy: 0.7291 - loss: 0.7746 - val_accuracy: 0.1407 - val_loss: 4.2808\n",
      "Epoch 3/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 337ms/step - accuracy: 0.8756 - loss: 0.4367 - val_accuracy: 0.1585 - val_loss: 4.0046\n",
      "Epoch 4/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 357ms/step - accuracy: 0.9484 - loss: 0.2249 - val_accuracy: 0.2613 - val_loss: 3.2164\n",
      "Epoch 5/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 331ms/step - accuracy: 0.9799 - loss: 0.1120 - val_accuracy: 0.3644 - val_loss: 2.5924\n",
      "Epoch 6/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 341ms/step - accuracy: 0.9915 - loss: 0.0616 - val_accuracy: 0.4938 - val_loss: 1.9546\n",
      "Epoch 7/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 339ms/step - accuracy: 0.9934 - loss: 0.0458 - val_accuracy: 0.6170 - val_loss: 1.4257\n",
      "Epoch 8/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 349ms/step - accuracy: 0.9933 - loss: 0.0395 - val_accuracy: 0.6267 - val_loss: 1.5562\n",
      "Epoch 9/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 343ms/step - accuracy: 0.9925 - loss: 0.0381 - val_accuracy: 0.7056 - val_loss: 1.1101\n",
      "Epoch 10/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 311ms/step - accuracy: 0.9844 - loss: 0.0570 - val_accuracy: 0.6959 - val_loss: 1.2084\n",
      "Epoch 11/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 316ms/step - accuracy: 0.9803 - loss: 0.0665 - val_accuracy: 0.7146 - val_loss: 1.1074\n",
      "Epoch 12/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 329ms/step - accuracy: 0.9893 - loss: 0.0394 - val_accuracy: 0.8087 - val_loss: 0.8340\n",
      "Epoch 13/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 333ms/step - accuracy: 0.9939 - loss: 0.0249 - val_accuracy: 0.7623 - val_loss: 1.1030\n",
      "Epoch 14/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 323ms/step - accuracy: 0.9946 - loss: 0.0220 - val_accuracy: 0.7881 - val_loss: 0.9944\n",
      "Epoch 15/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 321ms/step - accuracy: 0.9901 - loss: 0.0324 - val_accuracy: 0.7568 - val_loss: 1.1117\n",
      "Epoch 16/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 325ms/step - accuracy: 0.9870 - loss: 0.0405 - val_accuracy: 0.7448 - val_loss: 1.1415\n",
      "Epoch 17/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 335ms/step - accuracy: 0.9843 - loss: 0.0479 - val_accuracy: 0.7575 - val_loss: 1.0834\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e49d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(\"Final Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da790ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transfer_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b65085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history_transfer_cnn.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60634a2",
   "metadata": {},
   "source": [
    "### Same model but all layers frozen (for comparason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fafdf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_frz = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(96, 96, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "base_frz.trainable = False  # keep pretrained weights fixed\n",
    "\n",
    "model_frz = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(48,48,1)),\n",
    "    tf.keras.layers.Resizing(96, 96),\n",
    "    tf.keras.layers.Conv2D(3, (1,1)),  # convert grayscale -> 3 channels\n",
    "\n",
    "    base_frz,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model_frz.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bf2e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 254ms/step - accuracy: 0.2326 - loss: 1.9714 - val_accuracy: 0.3144 - val_loss: 1.5517\n",
      "Epoch 2/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 273ms/step - accuracy: 0.3275 - loss: 1.5411 - val_accuracy: 0.3417 - val_loss: 1.5131\n",
      "Epoch 3/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 268ms/step - accuracy: 0.3520 - loss: 1.5013 - val_accuracy: 0.3649 - val_loss: 1.4870\n",
      "Epoch 4/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 271ms/step - accuracy: 0.3693 - loss: 1.4744 - val_accuracy: 0.3723 - val_loss: 1.4711\n",
      "Epoch 5/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 275ms/step - accuracy: 0.3771 - loss: 1.4623 - val_accuracy: 0.3731 - val_loss: 1.4599\n",
      "Epoch 6/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 288ms/step - accuracy: 0.3884 - loss: 1.4468 - val_accuracy: 0.3862 - val_loss: 1.4498\n",
      "Epoch 7/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 284ms/step - accuracy: 0.3972 - loss: 1.4329 - val_accuracy: 0.3834 - val_loss: 1.4428\n",
      "Epoch 8/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 282ms/step - accuracy: 0.4056 - loss: 1.4216 - val_accuracy: 0.3876 - val_loss: 1.4373\n",
      "Epoch 9/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 281ms/step - accuracy: 0.4039 - loss: 1.4176 - val_accuracy: 0.3943 - val_loss: 1.4283\n",
      "Epoch 10/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 281ms/step - accuracy: 0.4052 - loss: 1.4099 - val_accuracy: 0.3978 - val_loss: 1.4235\n",
      "Epoch 11/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 275ms/step - accuracy: 0.4091 - loss: 1.4057 - val_accuracy: 0.3989 - val_loss: 1.4190\n",
      "Epoch 12/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 267ms/step - accuracy: 0.4121 - loss: 1.3991 - val_accuracy: 0.4017 - val_loss: 1.4142\n",
      "Epoch 13/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 270ms/step - accuracy: 0.4152 - loss: 1.3944 - val_accuracy: 0.4064 - val_loss: 1.4074\n",
      "Epoch 14/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 275ms/step - accuracy: 0.4218 - loss: 1.3846 - val_accuracy: 0.4085 - val_loss: 1.4056\n",
      "Epoch 15/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 283ms/step - accuracy: 0.4221 - loss: 1.3834 - val_accuracy: 0.4069 - val_loss: 1.4034\n",
      "Epoch 16/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 277ms/step - accuracy: 0.4239 - loss: 1.3782 - val_accuracy: 0.4124 - val_loss: 1.3988\n",
      "Epoch 17/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 282ms/step - accuracy: 0.4291 - loss: 1.3741 - val_accuracy: 0.4184 - val_loss: 1.3941\n",
      "Epoch 18/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 292ms/step - accuracy: 0.4278 - loss: 1.3712 - val_accuracy: 0.4160 - val_loss: 1.3919\n",
      "Epoch 19/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 295ms/step - accuracy: 0.4298 - loss: 1.3683 - val_accuracy: 0.4178 - val_loss: 1.3896\n",
      "Epoch 20/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 293ms/step - accuracy: 0.4319 - loss: 1.3651 - val_accuracy: 0.4163 - val_loss: 1.3892\n",
      "Epoch 21/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 289ms/step - accuracy: 0.4341 - loss: 1.3604 - val_accuracy: 0.4163 - val_loss: 1.3876\n",
      "Epoch 22/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 289ms/step - accuracy: 0.4348 - loss: 1.3578 - val_accuracy: 0.4141 - val_loss: 1.3870\n",
      "Epoch 23/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 289ms/step - accuracy: 0.4398 - loss: 1.3537 - val_accuracy: 0.4149 - val_loss: 1.3833\n",
      "Epoch 24/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 280ms/step - accuracy: 0.4375 - loss: 1.3536 - val_accuracy: 0.4236 - val_loss: 1.3809\n",
      "Epoch 25/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 280ms/step - accuracy: 0.4396 - loss: 1.3490 - val_accuracy: 0.4248 - val_loss: 1.3764\n",
      "Epoch 26/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 284ms/step - accuracy: 0.4373 - loss: 1.3484 - val_accuracy: 0.4211 - val_loss: 1.3763\n",
      "Epoch 27/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 287ms/step - accuracy: 0.4428 - loss: 1.3447 - val_accuracy: 0.4257 - val_loss: 1.3738\n",
      "Epoch 28/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - accuracy: 0.4430 - loss: 1.3447 - val_accuracy: 0.4301 - val_loss: 1.3733\n",
      "Epoch 29/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 286ms/step - accuracy: 0.4453 - loss: 1.3358 - val_accuracy: 0.4261 - val_loss: 1.3710\n",
      "Epoch 30/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 285ms/step - accuracy: 0.4458 - loss: 1.3377 - val_accuracy: 0.4235 - val_loss: 1.3704\n",
      "Epoch 31/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 290ms/step - accuracy: 0.4476 - loss: 1.3342 - val_accuracy: 0.4219 - val_loss: 1.3697\n",
      "Epoch 32/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 285ms/step - accuracy: 0.4463 - loss: 1.3364 - val_accuracy: 0.4345 - val_loss: 1.3658\n",
      "Epoch 33/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 285ms/step - accuracy: 0.4494 - loss: 1.3303 - val_accuracy: 0.4335 - val_loss: 1.3646\n",
      "Epoch 34/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 287ms/step - accuracy: 0.4494 - loss: 1.3280 - val_accuracy: 0.4339 - val_loss: 1.3635\n",
      "Epoch 35/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3649s\u001b[0m 12s/step - accuracy: 0.4528 - loss: 1.3265 - val_accuracy: 0.4333 - val_loss: 1.3626\n",
      "Epoch 36/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 266ms/step - accuracy: 0.4533 - loss: 1.3236 - val_accuracy: 0.4283 - val_loss: 1.3629\n",
      "Epoch 37/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 254ms/step - accuracy: 0.4534 - loss: 1.3248 - val_accuracy: 0.4250 - val_loss: 1.3638\n",
      "Epoch 38/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 264ms/step - accuracy: 0.4543 - loss: 1.3235 - val_accuracy: 0.4320 - val_loss: 1.3603\n",
      "Epoch 39/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 274ms/step - accuracy: 0.4528 - loss: 1.3224 - val_accuracy: 0.4396 - val_loss: 1.3576\n",
      "Epoch 40/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 274ms/step - accuracy: 0.4562 - loss: 1.3198 - val_accuracy: 0.4331 - val_loss: 1.3588\n",
      "Epoch 41/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 273ms/step - accuracy: 0.4524 - loss: 1.3187 - val_accuracy: 0.4358 - val_loss: 1.3583\n",
      "Epoch 42/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 275ms/step - accuracy: 0.4557 - loss: 1.3190 - val_accuracy: 0.4380 - val_loss: 1.3552\n",
      "Epoch 43/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 276ms/step - accuracy: 0.4602 - loss: 1.3166 - val_accuracy: 0.4340 - val_loss: 1.3557\n",
      "Epoch 44/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 276ms/step - accuracy: 0.4566 - loss: 1.3159 - val_accuracy: 0.4415 - val_loss: 1.3533\n",
      "Epoch 45/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 276ms/step - accuracy: 0.4621 - loss: 1.3099 - val_accuracy: 0.4403 - val_loss: 1.3531\n",
      "Epoch 46/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 277ms/step - accuracy: 0.4603 - loss: 1.3079 - val_accuracy: 0.4382 - val_loss: 1.3533\n",
      "Epoch 47/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 279ms/step - accuracy: 0.4596 - loss: 1.3117 - val_accuracy: 0.4419 - val_loss: 1.3514\n",
      "Epoch 48/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 276ms/step - accuracy: 0.4625 - loss: 1.3066 - val_accuracy: 0.4388 - val_loss: 1.3518\n",
      "Epoch 49/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 276ms/step - accuracy: 0.4628 - loss: 1.3075 - val_accuracy: 0.4418 - val_loss: 1.3497\n",
      "Epoch 50/50\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 277ms/step - accuracy: 0.4652 - loss: 1.3061 - val_accuracy: 0.4425 - val_loss: 1.3491\n"
     ]
    }
   ],
   "source": [
    "history_frz = model_frz.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4181d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_frz.save('transfer_frozen_cnn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369acf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"history_transfer_cnn_frozen.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history_frz.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4655be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
